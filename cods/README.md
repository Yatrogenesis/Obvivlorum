# ğŸ§  SIMBIOSIS OBVIVLORUM

Sistema hologrÃ¡fico de IA con memoria persistente que integra un LLM local con un mÃ³dulo de kernel para almacenamiento de patrones.

## ğŸ¯ CaracterÃ­sticas

- **Memoria HologrÃ¡fica**: MÃ³dulo kernel `holomem` para almacenamiento persistente de patrones
- **IA Local**: Utiliza modelos Llama locales (sin conexiÃ³n a internet)
- **Interfaz Intuitiva**: CLI con sÃ­ntesis de voz y comandos especiales
- **Multiplataforma**: Funciona en Windows con WSL2 + Kali Linux

## ğŸ“¦ Modelos Disponibles

El sistema puede usar cualquiera de estos modelos (ya incluidos):

| Modelo | TamaÃ±o | Velocidad | Calidad | Recomendado |
|--------|--------|-----------|---------|-------------|
| Llama-3.2-1B | 773MB | âš¡âš¡âš¡ | â­â­ | Para sistemas lentos |
| **Llama-3.2-3B** | 1.9GB | âš¡âš¡ | â­â­â­ | **âœ… Por defecto** |
| Meta-Llama-3-8B | 4.6GB | âš¡ | â­â­â­â­ | Para mejor calidad |
| Phi-3-mini | 2.4GB | âš¡âš¡ | â­â­â­ | Alternativo |

## ğŸš€ InstalaciÃ³n RÃ¡pida

### OpciÃ³n 1: InstalaciÃ³n AutomÃ¡tica
```powershell
# Ejecutar como administrador
.\cods\00_instalar_completo.ps1
```

### OpciÃ³n 2: InstalaciÃ³n Manual
```powershell
# Paso a paso
.\cods\01_instalar_WSL2_y_Kali.ps1
.\cods\03_generar_archivos_fuente.ps1  
.\cods\02_instalar_holomem.ps1
.\cods\04_instalar_llama_cpp.ps1
.\cods\05_middleware_e_interfaz.ps1
```

## ğŸ® Uso

### Lanzar el Sistema
```powershell
.\cods\06_lanzar_simbiosis.ps1
```

### Comandos Disponibles
- `Â¿QuÃ© es la IA?` - Pregunta normal
- `/memoria` - Ver patrones almacenados
- `/salir` - Terminar sesiÃ³n

### Ejemplo de SesiÃ³n
```
ğŸ§  TÃº: Â¿CuÃ¡l es el sentido de la vida?
ğŸ¤– Procesando con Llama-3.2-3B...
ğŸ¤– IA: El sentido de la vida es una pregunta fundamental...
ğŸ’¾ PatrÃ³n almacenado: Conversacion

ğŸ§  TÃº: /memoria
ğŸ“š Memoria hologrÃ¡fica:
[Conversacion] P:5 Size:234 - Q: Â¿CuÃ¡l es el sentido de la vida? A: El sentido...
```

## ğŸ”§ Arquitectura TÃ©cnica

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Windows CLI   â”‚â”€â”€â”€â–¶â”‚  WSL2 + Kali     â”‚â”€â”€â”€â–¶â”‚  Kernel Module  â”‚
â”‚   (PowerShell)  â”‚    â”‚  (Python + C++)  â”‚    â”‚   (holomem)     â”‚ 
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€ llama.cpp â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€ /proc/holomem â”€â”€â”˜
```

### Componentes

1. **holomem.ko**: MÃ³dulo kernel para almacenamiento de patrones
2. **holomem-util**: Utilidad CLI para interactuar con el mÃ³dulo
3. **llama.cpp**: Motor de inferencia para modelos LLM
4. **simbiosis_cli.py**: Interfaz principal con sÃ­ntesis de voz

## ğŸ› ï¸ Desarrollo

### Estructura de Archivos
```
cods/
â”œâ”€â”€ 00_instalar_completo.ps1     # ğŸ¯ Script maestro
â”œâ”€â”€ 01_instalar_WSL2_y_Kali.ps1  # ConfiguraciÃ³n base
â”œâ”€â”€ 02_instalar_holomem.ps1      # CompilaciÃ³n mÃ³dulo
â”œâ”€â”€ 03_generar_archivos_fuente.ps1 # CÃ³digo fuente
â”œâ”€â”€ 04_instalar_llama_cpp.ps1    # Motor LLM
â”œâ”€â”€ 05_middleware_e_interfaz.ps1 # Interfaz Python
â””â”€â”€ 06_lanzar_simbiosis.ps1      # Lanzador
```

### PersonalizaciÃ³n de Modelo

Para cambiar el modelo LLM, edita el script 4:
```powershell
# En 04_instalar_llama_cpp.ps1
$sourcePath = "D:\Obvivlorum\LLMs\Meta-Llama-3-8B-Instruct.Q4_0.gguf"  # Cambiar aquÃ­
```

## ğŸ” SoluciÃ³n de Problemas

### Error: "VirtualizaciÃ³n NO estÃ¡ activada"
- Activar VT-x/AMD-V en BIOS
- Reiniciar y volver a ejecutar

### Error: "No se encontrÃ³ Kali Linux"
- Instalar desde Microsoft Store
- Configurar usuario inicial

### Error: "MÃ³dulo holomem no carga"
```bash
# Verificar en WSL
sudo dmesg | grep holomem
lsmod | grep holomem
```

### Error: "Modelo no responde"
- Verificar que el archivo .gguf existe
- Comprobar permisos de lectura
- Probar con modelo mÃ¡s pequeÃ±o

## ğŸ¨ PersonalizaciÃ³n

### Cambiar Velocidad de Voz
```python
# En simbiosis_cli.py
engine.setProperty("rate", 120)  # MÃ¡s lento
engine.setProperty("rate", 180)  # MÃ¡s rÃ¡pido
```

### Agregar Comandos Personalizados
```python
# En simbiosis_cli.py
if prompt.lower() == "/ayuda":
    print("ğŸ†˜ Comandos disponibles: /memoria, /salir")
    continue
```

## ğŸ“Š Rendimiento

| Componente | RAM | CPU | Tiempo Respuesta |
|------------|-----|-----|------------------|
| Llama-3.2-1B | 1GB | Bajo | 2-5s |
| Llama-3.2-3B | 3GB | Medio | 5-10s |
| Meta-Llama-8B | 6GB | Alto | 10-20s |

## ğŸ¤ ContribuciÃ³n

1. Fork del repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“œ Licencia

GPL v3 - Software libre para uso, modificaciÃ³n y distribuciÃ³n.

## ğŸ† CrÃ©ditos

- **LLaMA**: Meta AI
- **llama.cpp**: Georgi Gerganov
- **WSL2**: Microsoft
- **Kali Linux**: Offensive Security

---
*ğŸ§  "La simbiosis entre humano y mÃ¡quina comienza con la memoria compartida"*